{
  "name": "Predictive Business Process Monitoring with LSTM Neural Networks",
  "tagline": "Supplementary material for the paper submitted to CAiSE '17",
  "body": "Following is the supplementary material for the article [\"Predictive Business Process Monitoring with\r\nLSTM Neural Networks\"](https://arxiv.org/abs/1612.02130) by Niek Tax, Ilya Verenich, [Marcello La Rosa](http://www.marcellolarosa.com/) and [Marlon Dumas](http://kodu.ut.ee/~dumas/).\r\n\r\nThe code provided in this repository can be readily used to perform the following predictive tasks:\r\n* Prediction of the next type of activity to be executed in a running process instance\r\n* Prediction of the timestamp of the next type of activity to be executed\r\n* Prediction of the continuation of a running instance, i.e. its suffix\r\n* Prediction of the remaining cycle time of an instance\r\n\r\nThe scripts trains a [Long Short Term Memory (LSTM)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)-based predictive model using the data about historical, i.e. completed process instances. Next, the models are evaluated on running, i.e. incomplete instances.\r\n\r\n**Requirements:**   \r\nPython 2. Additionally, the following Python libraries are required to run the code: [_keras_](https://keras.io/) (as a backend, you need either _theano_ or _tensorflow_), _unicodecsv_, _numpy_, _jellyfish_, _sklearn_, _matplotlib_, _h5py_.  \r\nNote you might need the latest version of _keras_ to run the code. Install it as:    \r\n`pip install git+git://github.com/fchollet/keras.git`\r\n\r\n**USAGE:**  \r\n**Data format**   \r\nThe tool assumes the input is a complete log of all traces in the CSV format wherein the first column is a case ID, then activity name or ID and finally the activity timestamp. Then, this input log is temporally split on 66% (training set) vs 34% (test set), and on the test set the tool evaluates prediction performance for every size of a partial trace, e.g a test trace cut at the 2nd event, the same trace cut at the 3rd event and so on, along all four prediction tasks. We provide sample datasets, including those used in the paper, in the _data_ folder.\r\n\r\n**Model training:**   \r\n`python train.py`    \r\nThis script trains a two-layer LSTM model with one shared layer on one of the data files in the data folder of this repository (by default, on the [_helpdesk_ event log](https://data.mendeley.com/datasets/39bp3vv62t/1)). To change the input file to another one from the data folder, indicate its name in line 46. It is recommended to run this script on GPU, as recurrent networks are quite computationally intensive. \r\n\r\n**Evaluation:**  \r\n`python evaluate_next_activity_and_time.py`   \r\nThis script takes as input the LSTM or RNN weights found by `train.py` and predicts the next event and its relative timestep for a partial trace. Change the path in line 176 of this script to point to the h5 file with LSTM or RNN weights generated by train.py. As an example, we provide the file _model_89-1.50.h5_ with one of the trained models\r\n\r\n`python evaluate_suffix_and_remaining_time.py`   \r\nThis script predicts the continuation of a partial trace, i.e. its suffix, until its completion.\r\n\r\n`python calculate_accuracy_on_next_event.py`.\r\nThis script evaluates the performance of the next event prediction (not the whole suffix). It takes the output of `evaluate_suffix_and_remaining_time.py` as input, therefore, the latter needs to be executed first\r\n\r\n**Known issues:**\r\n* If you receive an error _UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa7' in position 0: ordinal not in range(128)_, make sure you are using the latest version of the _jellyfish_ package (0.5.6 should work fine)",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}